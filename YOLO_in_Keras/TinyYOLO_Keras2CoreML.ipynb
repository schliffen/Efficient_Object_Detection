{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Machine Learning with Core ML](https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-core-ml)\n",
    "**By:** Joshua Newnham (Author)  \n",
    "**Publisher:** [Packt Publishing](https://www.packtpub.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5 - Object Detection using [TinyYOLO2](https://pjreddie.com/darknet/yolov2/) \n",
    "\n",
    "In this notebook we will use the [Core ML Tools Python](https://github.com/apple/coremltools) package to export a YOLO Keras model. YOLO (You Only Look Once) is a performant network that can achieve real-time object detection (object detection meaning the ability to classify and locate multiple objects). Here we have used a varaint of the YOLOv2 architecture called TinyYOLO; as the name suggests, this is a cut-down version of the full network, applicable for smartphone applications. \n",
    "\n",
    "To learn more about YOLO - I point you to the official site and paper, shown below: \n",
    "- https://pjreddie.com/darknet/yolov2/\n",
    "- YOLO9000: Better, Faster, Stronger https://arxiv.org/abs/1612.08242 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB: To run locally;** create the environment from the *coreml27_environment.yml* file in this directory. Details of how to do this can be found [here](https://conda.io/docs/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Ensure that coremltools modules are installed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install coremltools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Import depedencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    import coremltools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Load model and weights from disk and create convert Keras model to an instance of *coremltools.models.MLModel*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following describes the parameters passed to the *convert* function (taken from the official website); to learn more about the parameters available please refer to the project website. \n",
    "- **model:** A trained Keras neural network model which can be a Keras model object, a string with the path to a Keras, or  model file (h5)a tuple of strings, where the first is the path to a Keras model\n",
    "- **input_names:** Optional name(s) that can be given to the inputs of the Keras model. These names will be used in the interface of the Core ML models to refer to the inputs of the Keras model. If not provided, the Keras inputs are named to [input1, input2, …, inputN] in the Core ML model. When multiple inputs are present, the input feature names are in the same order as the Keras inputs.\n",
    "- **image_input_names:** Input names to the Keras model (a subset of the input_names parameter) that can be treated as images by Core ML. All other inputs are treated as MultiArrays (N-D Arrays).\n",
    "- **output_names:** Optional name(s) that can be given to the outputs of the Keras model. These names will be used in the interface of the Core ML models to refer to the outputs of the Keras model. If not provided, the Keras outputs are named to [output1, output2, …, outputN] in the Core ML model. When multiple outputs are present, output feature names are in the same order as the Keras inputs.\n",
    "- **image_scale:** Value by which input images will be scaled before bias is added and Core ML model makes a prediction. Defaults to 1.0. Applicable only if image_input_names is specified. To specify different values for each image input provide a dictionary with input names as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/coreml27/lib/python2.7/site-packages/keras/models.py:251: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : input_1, <keras.engine.topology.InputLayer object at 0x11025f3d0>\n",
      "1 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x108f37b50>\n",
      "2 : batch_normalization_1, <keras.layers.normalization.BatchNormalization object at 0x108f37d50>\n",
      "3 : leaky_re_lu_1, <keras.layers.advanced_activations.LeakyReLU object at 0x11025f7d0>\n",
      "4 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x11025f650>\n",
      "5 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x11025f610>\n",
      "6 : batch_normalization_2, <keras.layers.normalization.BatchNormalization object at 0x11025f850>\n",
      "7 : leaky_re_lu_2, <keras.layers.advanced_activations.LeakyReLU object at 0x11025fa50>\n",
      "8 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x11025fa90>\n",
      "9 : conv2d_3, <keras.layers.convolutional.Conv2D object at 0x11025fc10>\n",
      "10 : batch_normalization_3, <keras.layers.normalization.BatchNormalization object at 0x11025ff50>\n",
      "11 : leaky_re_lu_3, <keras.layers.advanced_activations.LeakyReLU object at 0x11025fed0>\n",
      "12 : max_pooling2d_3, <keras.layers.pooling.MaxPooling2D object at 0x11029d0d0>\n",
      "13 : conv2d_4, <keras.layers.convolutional.Conv2D object at 0x11029d150>\n",
      "14 : batch_normalization_4, <keras.layers.normalization.BatchNormalization object at 0x11029d190>\n",
      "15 : leaky_re_lu_4, <keras.layers.advanced_activations.LeakyReLU object at 0x11029d290>\n",
      "16 : max_pooling2d_4, <keras.layers.pooling.MaxPooling2D object at 0x11029d3d0>\n",
      "17 : conv2d_5, <keras.layers.convolutional.Conv2D object at 0x11029d450>\n",
      "18 : batch_normalization_5, <keras.layers.normalization.BatchNormalization object at 0x11029d490>\n",
      "19 : leaky_re_lu_5, <keras.layers.advanced_activations.LeakyReLU object at 0x11029d590>\n",
      "20 : max_pooling2d_5, <keras.layers.pooling.MaxPooling2D object at 0x11029d6d0>\n",
      "21 : conv2d_6, <keras.layers.convolutional.Conv2D object at 0x11029d750>\n",
      "22 : batch_normalization_6, <keras.layers.normalization.BatchNormalization object at 0x11029d790>\n",
      "23 : leaky_re_lu_6, <keras.layers.advanced_activations.LeakyReLU object at 0x11029d890>\n",
      "24 : max_pooling2d_6, <keras.layers.pooling.MaxPooling2D object at 0x11029d9d0>\n",
      "25 : conv2d_7, <keras.layers.convolutional.Conv2D object at 0x11029da50>\n",
      "26 : batch_normalization_7, <keras.layers.normalization.BatchNormalization object at 0x11029da90>\n",
      "27 : leaky_re_lu_7, <keras.layers.advanced_activations.LeakyReLU object at 0x11029db90>\n",
      "28 : conv2d_8, <keras.layers.convolutional.Conv2D object at 0x11029dcd0>\n",
      "29 : batch_normalization_8, <keras.layers.normalization.BatchNormalization object at 0x11029dd10>\n",
      "30 : leaky_re_lu_8, <keras.layers.advanced_activations.LeakyReLU object at 0x11029de10>\n",
      "31 : conv2d_9, <keras.layers.convolutional.Conv2D object at 0x11029df50>\n"
     ]
    }
   ],
   "source": [
    "coreml_model = coremltools.converters.keras.convert(\n",
    "    'tinyyolo_voc2007_modelweights.h5',\n",
    "    input_names='image',\n",
    "    image_input_names='image',\n",
    "    output_names='output',\n",
    "    image_scale=1./255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Add metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, the *Core ML model* defines a specification consists of:\n",
    "- **Model description:** Encodes names and type information of the inputs and outputs to the model.\n",
    "- **Model parameters:** The set of parameters required to represent a specific instance of the model.\n",
    "- **Metadata:** Information about the origin, license, and author of the model.\n",
    "\n",
    "With this class, you can inspect a CoreML model, modify metadata (shown below), and make predictions for the purposes of testing using the [**predict** function](https://apple.github.io/coremltools/generated/coremltools.models.MLModel.html?highlight=metadata#coremltools.models.MLModel.predict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model.author = 'Joshua Newnham'\n",
    "coreml_model.license = 'BSD'\n",
    "coreml_model.short_description = 'Keras port of YOLOTiny VOC2007 by Joseph Redmon and Ali Farhadi'\n",
    "coreml_model.input_description['image'] = '416x416 RGB Image'\n",
    "coreml_model.output_description['output'] = '13x13 Grid made up of: [confidence, cx, cy, w, h, 20 x classes] * 5 bounding boxes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Save to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model.save('tinyyolo_voc2007.mlmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [The PASCAL Visual Object Classes Challenge 2007](http://host.robots.ox.ac.uk:8080/pascal/VOC/voc2007/index.html)\n",
    "- [Official YOLO website](https://pjreddie.com/darknet/yolo/)\n",
    "- [Official Core ML Tools website](https://apple.github.io/coremltools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreml27",
   "language": "python",
   "name": "coreml27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
